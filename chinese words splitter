import streamlit as st
import jieba
import requests
import json
from urllib.parse import quote
import time
import re
from typing import Dict, List, Tuple, Optional

# Configure page
st.set_page_config(
    page_title="Chinese Text Analyzer",
    page_icon="ğŸ”",
    layout="wide"
)

# Custom CSS for larger fonts
st.markdown("""
<style>
    .big-font {
        font-size: 42px !important;
        font-weight: bold;
        color: #1f77b4;
    }
    .medium-font {
        font-size: 32px !important;
        font-weight: bold;
    }
    .chinese-char {
        font-size: 48px !important;
        font-weight: bold;
        color: #1f77b4;
        font-family: 'SimHei', 'Microsoft YaHei', 'PingFang SC', 'Hiragino Sans GB', sans-serif;
    }
    .chinese-word {
        font-size: 44px !important;
        font-weight: bold;
        color: #d62728;
        font-family: 'SimHei', 'Microsoft YaHei', 'PingFang SC', 'Hiragino Sans GB', sans-serif;
    }
    .meaning {
        font-size: 26px !important;
        color: #2ca02c;
        font-weight: 500;
        margin: 10px 0;
    }
    .pinyin {
        font-size: 24px !important;
        color: #ff7f0e;
        font-style: italic;
        font-weight: bold;
        margin: 8px 0;
    }
    .sentence-box {
        border: 4px solid #9b59b6;
        border-radius: 15px;
        padding: 35px;
        margin: 25px 0;
        background: linear-gradient(135deg, #e8f4fd 0%, #c7e0f4 100%);
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.15);
    }
    .sentence-text {
        font-size: 40px !important;
        font-weight: bold;
        color: #2c3e50;
        text-align: center;
        margin: 15px 0;
        font-family: 'SimHei', 'Microsoft YaHei', 'PingFang SC', 'Hiragino Sans GB', sans-serif;
    }
    .sentence-pinyin {
        font-size: 28px !important;
        color: #e74c3c;
        font-style: italic;
        font-weight: bold;
        text-align: center;
        margin: 15px 0;
        background: #fff3cd;
        padding: 10px;
        border-radius: 8px;
    }
    .sentence-meaning {
        font-size: 28px !important;
        color: #27ae60;
        font-weight: 600;
        text-align: center;
        margin: 15px 0;
    }
    .analysis-box {
        border: 3px solid #e0e0e0;
        border-radius: 15px;
        padding: 30px;
        margin: 20px 0;
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .character-box {
        border: 3px solid #1f77b4;
        border-radius: 12px;
        padding: 25px;
        margin: 12px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        text-align: center;
        min-width: 160px;
        min-height: 140px;
        display: flex;
        flex-direction: column;
        justify-content: center;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
    }
    .word-box {
        border: 3px solid #d62728;
        border-radius: 12px;
        padding: 30px;
        margin: 20px 0;
        background: linear-gradient(135deg, #ffeaa7 0%, #fab1a0 100%);
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    }
    .combination-text {
        font-size: 28px !important;
        font-weight: bold;
        background: linear-gradient(45deg, #667eea, #764ba2);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    .debug-info {
        background-color: #f0f0f0;
        padding: 10px;
        border-radius: 5px;
        font-size: 14px;
        margin: 5px 0;
    }
    .pinyin-highlight {
        background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 50%, #fecfef 100%);
        padding: 8px 12px;
        border-radius: 6px;
        font-size: 22px !important;
        font-weight: bold;
        color: #333;
    }
    .success-badge {
        background: #28a745;
        color: white;
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 12px;
        margin-left: 10px;
    }
    .error-badge {
        background: #dc3545;
        color: white;
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 12px;
        margin-left: 10px;
    }
</style>
""", unsafe_allow_html=True)

class ComprehensivePinyinConverter:
    def __init__(self):
        self.cache = {}
        self.translation_cache = {}
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7'
        })
        
        # Comprehensive built-in pinyin dictionary
        self.pinyin_dict = self._load_comprehensive_pinyin_dict()
        
    def _load_comprehensive_pinyin_dict(self) -> Dict[str, str]:
        """Load a comprehensive pinyin dictionary"""
        return {
            # Basic characters
            'çš„': 'de', 'ä¸€': 'yÄ«', 'æ˜¯': 'shÃ¬', 'ä¸': 'bÃ¹', 'äº†': 'le', 'äºº': 'rÃ©n', 'æˆ‘': 'wÇ’', 
            'åœ¨': 'zÃ i', 'æœ‰': 'yÇ’u', 'ä»–': 'tÄ', 'è¿™': 'zhÃ¨', 'å€‹': 'gÃ¨', 'ä¸ª': 'gÃ¨', 'ä»¬': 'men', 
            'ä¸­': 'zhÅng', 'æ¥': 'lÃ¡i', 'ä¾†': 'lÃ¡i', 'ä¸Š': 'shÃ ng', 'å¤§': 'dÃ ', 'ä¸º': 'wÃ©i', 
            'ç‚º': 'wÃ©i', 'å’Œ': 'hÃ©', 'å›½': 'guÃ³', 'åœ‹': 'guÃ³', 'åœ°': 'dÃ¬', 'åˆ°': 'dÃ o', 
            'ä»¥': 'yÇ', 'è¯´': 'shuÅ', 'èªª': 'shuÅ', 'æ—¶': 'shÃ­', 'æ™‚': 'shÃ­', 'è¦': 'yÃ o', 
            'å°±': 'jiÃ¹', 'å‡º': 'chÅ«', 'ä¼š': 'huÃ¬', 'æœƒ': 'huÃ¬', 'å¯': 'kÄ›', 'ä¹Ÿ': 'yÄ›', 
            'ä½ ': 'nÇ', 'å¯¹': 'duÃ¬', 'å°': 'duÃ¬', 'ç”Ÿ': 'shÄ“ng', 'èƒ½': 'nÃ©ng', 'è€Œ': 'Ã©r', 
            'å­': 'zi', 'é‚£': 'nÃ ', 'å¾—': 'dÃ©', 'äº': 'yÃº', 'æ–¼': 'yÃº', 'ç€': 'zhe', 
            'è‘—': 'zhe', 'ä¸‹': 'xiÃ ', 'è‡ª': 'zÃ¬', 'ä¹‹': 'zhÄ«', 'å¹´': 'niÃ¡n', 'è¿‡': 'guÃ²', 
            'é': 'guÃ²', 'å‘': 'fÄ', 'ç™¼': 'fÄ', 'å': 'hÃ²u', 'å¾Œ': 'hÃ²u', 'ä½œ': 'zuÃ²', 
            'é‡Œ': 'lÇ', 'è£¡': 'lÇ', 'ç”¨': 'yÃ²ng', 'é“': 'dÃ o', 'è¡Œ': 'xÃ­ng', 'æ‰€': 'suÇ’', 
            'ç„¶': 'rÃ¡n', 'å®¶': 'jiÄ', 'ç§': 'zhÇ’ng', 'ç¨®': 'zhÇ’ng', 'äº‹': 'shÃ¬', 'æ–¹': 'fÄng', 
            'å¤š': 'duÅ', 'ç»': 'jÄ«ng', 'ç¶“': 'jÄ«ng', 'ä¹ˆ': 'me', 'éº¼': 'me', 'å»': 'qÃ¹', 
            'æ³•': 'fÇ', 'å­¦': 'xuÃ©', 'å­¸': 'xuÃ©', 'å¦‚': 'rÃº', 'å¥¹': 'tÄ', 'çœ‹': 'kÃ n', 
            'å¤©': 'tiÄn', 'æ ·': 'yÃ ng', 'æ¨£': 'yÃ ng', 'å…¶': 'qÃ­', 'æ–°': 'xÄ«n', 'æ‰‹': 'shÇ’u', 
            'åˆ': 'yÃ²u', 'å½“': 'dÄng', 'ç•¶': 'dÄng', 'æ²¡': 'mÃ©i', 'æ²’': 'mÃ©i', 'åŠ¨': 'dÃ²ng', 
            'å‹•': 'dÃ²ng', 'é¢': 'miÃ n', 'èµ·': 'qÇ', 'è€': 'lÇo', 'å…¬': 'gÅng', 'é«˜': 'gÄo', 
            'æƒ³': 'xiÇng', 'å°': 'xiÇo', 'ä»': 'cÃ³ng', 'å¾': 'cÃ³ng', 'å¼€': 'kÄi', 'é–‹': 'kÄi', 
            'å¤´': 'tÃ³u', 'é ­': 'tÃ³u', 'ç­‰': 'dÄ›ng', 'é•¿': 'chÃ¡ng', 'é•·': 'chÃ¡ng', 'æ°´': 'shuÇ', 
            'å‡ ': 'jÇ', 'å¹¾': 'jÇ', 'æ°‘': 'mÃ­n', 'ç°': 'xiÃ n', 'ç¾': 'xiÃ n', 'å±±': 'shÄn', 
            'åˆ†': 'fÄ“n', 'æœ›': 'wÃ ng', 'ç¬¬': 'dÃ¬', 'ä½': 'wÃ¨i', 'æ¯”': 'bÇ', 'è·¯': 'lÃ¹', 
            'ç¥': 'shÃ©n', 'å¤ª': 'tÃ i', 'æœº': 'jÄ«', 'æ©Ÿ': 'jÄ«', 'å®‰': 'Än',
            
            # Common words and phrases
            'é€‚': 'shÃ¬', 'é©': 'shÃ¬', 'åˆ': 'hÃ©', 'å·¥': 'gÅng', 'ç­': 'bÄn', 'éœ€': 'xÅ«', 
            'å¸®': 'bÄng', 'å¹«': 'bÄng', 'åŠ©': 'zhÃ¹', 'æ€»': 'zÇ’ng', 'ç¸½': 'zÇ’ng', 'ç»Ÿ': 'tÇ’ng', 
            'çµ±': 'tÇ’ng', 'åºœ': 'fÇ”', 'çˆ±': 'Ã i', 'æ„›': 'Ã i', 'åŒ—': 'bÄ›i', 'äº¬': 'jÄ«ng', 
            'è°¢': 'xiÃ¨', 'è¬': 'xiÃ¨', 'å¥½': 'hÇo', 'ä¸–': 'shÃ¬', 'ç•Œ': 'jiÃ¨', 'ä»Š': 'jÄ«n', 
            'æ°”': 'qÃ¬', 'æ°£': 'qÃ¬', 'å¾ˆ': 'hÄ›n', 'å¿™': 'mÃ¡ng', 'ç¢Œ': 'lÃ¹', 'æ±‰': 'hÃ n', 
            'æ¼¢': 'hÃ n', 'è¯­': 'yÇ”', 'èª': 'yÇ”', 'ä¹ ': 'xÃ­', 'ç¿’': 'xÃ­', 'å¬': 'tÄ«ng', 
            'è½': 'tÄ«ng', 'åƒ': 'chÄ«', 'å–': 'hÄ“', 'èµ°': 'zÇ’u', 'è·‘': 'pÇo', 'ç«™': 'zhÃ n', 
            'å': 'zuÃ²', 'ç¡': 'shuÃ¬', 'ä¹¦': 'shÅ«', 'æ›¸': 'shÅ«', 'ç”µ': 'diÃ n', 'é›»': 'diÃ n', 
            'è¯': 'huÃ ', 'è©±': 'huÃ ', 'ä¹°': 'mÇi', 'è²·': 'mÇi', 'å–': 'mÃ i', 'è³£': 'mÃ i', 
            'é’±': 'qiÃ¡n', 'éŒ¢': 'qiÃ¡n', 'è½¦': 'chÄ“', 'è»Š': 'chÄ“', 'ä½': 'zhÃ¹', 'è¯·': 'qÇng', 
            'è«‹': 'qÇng', 'ä»€': 'shÃ©n', 'å“ª': 'nÇ', 'æ€': 'zÄ›n', 'å°‘': 'shÇo', 'æ—§': 'jiÃ¹', 
            'èˆŠ': 'jiÃ¹', 'çŸ­': 'duÇn', 'ä½': 'dÄ«', 'å¿«': 'kuÃ i', 'æ…¢': 'mÃ n', 'çœ¼': 'yÇn', 
            'è€³': 'Ä›r', 'å£': 'kÇ’u', 'é¼»': 'bÃ­', 'å¿ƒ': 'xÄ«n', 'è„š': 'jiÇo', 'è…³': 'jiÇo',
            
            # Additional characters
            'æ–‡': 'wÃ©n', 'åŒ–': 'huÃ ', 'æ•™': 'jiÃ o', 'è‚²': 'yÃ¹', 'éŸ³': 'yÄ«n', 'ä¹': 'lÃ¨', 
            'æ¨‚': 'lÃ¨', 'ç”µ': 'diÃ n', 'å½±': 'yÇng', 'é™¢': 'yuÃ n', 'åŒ»': 'yÄ«', 'é†«': 'yÄ«', 
            'ç”Ÿ': 'shÄ“ng', 'æŠ¤': 'hÃ¹', 'è­·': 'hÃ¹', 'å£«': 'shÃ¬', 'é“¶': 'yÃ­n', 'éŠ€': 'yÃ­n', 
            'è¡Œ': 'hÃ¡ng', 'åº—': 'diÃ n', 'é¥­': 'fÃ n', 'é£¯': 'fÃ n', 'é¦†': 'guÇn', 'é¤¨': 'guÇn', 
            'å®¾': 'bÄ«n', 'è³“': 'bÄ«n', 'èœ': 'cÃ i', 'è‚‰': 'rÃ²u', 'é±¼': 'yÃº', 'é­š': 'yÃº', 
            'ç‰›': 'niÃº', 'çŒª': 'zhÅ«', 'è±¬': 'zhÅ«', 'é¸¡': 'jÄ«', 'é›': 'jÄ«', 'è›‹': 'dÃ n', 
            'ç±³': 'mÇ', 'é¢': 'miÃ n', 'éºµ': 'miÃ n', 'åŒ…': 'bÄo', 'èŒ¶': 'chÃ¡', 'å’–': 'kÄ', 
            'å•¡': 'fÄ“i', 'é…’': 'jiÇ”', 'æœ': 'guÇ’', 'èœ': 'cÃ i', 'èŠ±': 'huÄ', 'æ ‘': 'shÃ¹', 
            'æ¨¹': 'shÃ¹', 'è‰': 'cÇo', 'é¸Ÿ': 'niÇo', 'é³¥': 'niÇo', 'ç‹—': 'gÇ’u', 'çŒ«': 'mÄo', 
            'è²“': 'mÄo', 'é©¬': 'mÇ', 'é¦¬': 'mÇ', 'ç‰›': 'niÃº', 'ç¾Š': 'yÃ¡ng', 'ç«': 'huÇ’', 
            'åœŸ': 'tÇ”', 'é‡‘': 'jÄ«n', 'æœ¨': 'mÃ¹', 'çŸ³': 'shÃ­', 'æ—¥': 'rÃ¬', 'æœˆ': 'yuÃ¨', 
            'æ˜Ÿ': 'xÄ«ng', 'äº‘': 'yÃºn', 'é›²': 'yÃºn', 'é›¨': 'yÇ”', 'é›ª': 'xuÄ›', 'é£': 'fÄ“ng', 
            'é¢¨': 'fÄ“ng', 'æ˜¥': 'chÅ«n', 'å¤': 'xiÃ ', 'ç§‹': 'qiÅ«', 'å†¬': 'dÅng', 'æ—©': 'zÇo', 
            'æ™š': 'wÇn', 'å¤œ': 'yÃ¨', 'åˆ': 'wÇ”', 'æ™¨': 'chÃ©n', 'å¤•': 'xÄ«', 'é˜³': 'yÃ¡ng', 
            'é™½': 'yÃ¡ng', 'é˜´': 'yÄ«n', 'é™°': 'yÄ«n'
        }

    def get_pinyin_google_translate(self, text: str) -> Optional[str]:
        """Get pinyin using Google Translate API"""
        try:
            url = "https://translate.googleapis.com/translate_a/single"
            params = {
                'client': 'gtx',
                'sl': 'zh-CN',
                'tl': 'zh-Latn-pinyin',
                'dt': 'rm',
                'q': text
            }
            
            response = self.session.get(url, params=params, timeout=10)
            if response.status_code == 200:
                result = response.json()
                if result and len(result) > 2 and result[2]:
                    # Extract romanization
                    romanization = result[2]
                    if isinstance(romanization, list) and len(romanization) > 0:
                        pinyin_parts = []
                        for item in romanization:
                            if isinstance(item, list) and len(item) > 1:
                                pinyin_parts.append(item[1])
                        if pinyin_parts:
                            return ' '.join(pinyin_parts)
                            
                # Alternative extraction method
                if result and len(result) > 0 and isinstance(result[0], list):
                    for translation_item in result[0]:
                        if isinstance(translation_item, list) and len(translation_item) > 2:
                            if translation_item[2] and translation_item[2] != text:
                                potential_pinyin = translation_item[2]
                                if re.match(r'^[a-zA-ZÄÃ¡ÇÃ Ä“Ã©Ä›Ã¨Ä«Ã­ÇÃ¬ÅÃ³Ç’Ã²Å«ÃºÇ”Ã¹Ã¼Ç˜ÇšÇœ\s]+$', potential_pinyin):
                                    return potential_pinyin.strip()
        except Exception as e:
            pass
        return None

    def get_pinyin_baidu_fanyi(self, text: str) -> Optional[str]:
        """Alternative method using different translation approach"""
        try:
            # Use a different approach with MyMemory translation
            url = "https://api.mymemory.translated.net/get"
            params = {
                'q': text,
                'langpair': 'zh|en-pinyin'
            }
            
            response = self.session.get(url, params=params, timeout=8)
            if response.status_code == 200:
                result = response.json()
                if 'responseData' in result and 'translatedText' in result['responseData']:
                    translated = result['responseData']['translatedText']
                    # Check if it looks like pinyin
                    if re.match(r'^[a-zA-ZÄÃ¡ÇÃ Ä“Ã©Ä›Ã¨Ä«Ã­ÇÃ¬ÅÃ³Ç’Ã²Å«ÃºÇ”Ã¹Ã¼Ç˜ÇšÇœ\s]+$', translated):
                        return translated.strip()
        except Exception:
            pass
        return None

    def get_pinyin_character_by_character(self, text: str) -> str:
        """Get pinyin character by character using built-in dictionary"""
        pinyin_parts = []
        for char in text:
            if '\u4e00' <= char <= '\u9fff':  # Chinese character
                pinyin = self.pinyin_dict.get(char, None)
                if pinyin:
                    pinyin_parts.append(pinyin)
                else:
                    # Try to get single character pinyin from online
                    online_pinyin = self.get_pinyin_google_translate(char)
                    if online_pinyin and online_pinyin != char:
                        # Clean the result
                        cleaned = re.sub(r'[^\w\sÄÃ¡ÇÃ Ä“Ã©Ä›Ã¨Ä«Ã­ÇÃ¬ÅÃ³Ç’Ã²Å«ÃºÇ”Ã¹Ã¼Ç˜ÇšÇœ]', '', online_pinyin)
                        if cleaned:
                            self.pinyin_dict[char] = cleaned  # Cache for future use
                            pinyin_parts.append(cleaned)
                        else:
                            pinyin_parts.append(f"[{char}]")
                    else:
                        pinyin_parts.append(f"[{char}]")
            else:
                # Non-Chinese character, keep as is
                if char.strip():
                    pinyin_parts.append(char)
        
        return ' '.join(pinyin_parts)

    def get_comprehensive_pinyin(self, text: str) -> str:
        """Get pinyin using multiple methods with smart fallbacks"""
        if not text or not text.strip():
            return ""
            
        text = text.strip()
        
        # Check cache first
        if text in self.cache:
            return self.cache[text]
        
        # Method 1: For single characters, try built-in dictionary first
        if len(text) == 1 and '\u4e00' <= text <= '\u9fff':
            builtin_pinyin = self.pinyin_dict.get(text)
            if builtin_pinyin:
                self.cache[text] = builtin_pinyin
                return builtin_pinyin
        
        # Method 2: Try Google Translate
        google_result = self.get_pinyin_google_translate(text)
        if google_result and google_result != text:
            # Clean and validate
            cleaned = self._clean_pinyin(google_result)
            if cleaned and not self._contains_chinese(cleaned):
                self.cache[text] = cleaned
                return cleaned
        
        # Method 3: Try alternative translation service
        baidu_result = self.get_pinyin_baidu_fanyi(text)
        if baidu_result and baidu_result != text:
            cleaned = self._clean_pinyin(baidu_result)
            if cleaned and not self._contains_chinese(cleaned):
                self.cache[text] = cleaned
                return cleaned
        
        # Method 4: Character by character approach
        char_by_char_result = self.get_pinyin_character_by_character(text)
        if char_by_char_result and '[' not in char_by_char_result:
            self.cache[text] = char_by_char_result
            return char_by_char_result
        
        # Method 5: Final fallback - at least try to get some characters
        if len(text) > 1:
            partial_results = []
            for char in text:
                if '\u4e00' <= char <= '\u9fff':
                    char_pinyin = self.pinyin_dict.get(char, char)
                    partial_results.append(char_pinyin)
                else:
                    partial_results.append(char)
            
            result = ' '.join(partial_results)
            self.cache[text] = result
            return result
        
        # Ultimate fallback
        result = f"[pinyin: {text}]"
        self.cache[text] = result
        return result

    def _clean_pinyin(self, pinyin_text: str) -> str:
        """Clean and standardize pinyin text"""
        if not pinyin_text:
            return ""
        
        # Remove unwanted characters but keep pinyin tone marks
        cleaned = re.sub(r'[^\w\sÄÃ¡ÇÃ Ä“Ã©Ä›Ã¨Ä«Ã­ÇÃ¬ÅÃ³Ç’Ã²Å«ÃºÇ”Ã¹Ã¼Ç˜ÇšÇœ]', ' ', pinyin_text)
        # Remove extra spaces
        cleaned = ' '.join(cleaned.split())
        return cleaned.strip()

    def _contains_chinese(self, text: str) -> bool:
        """Check if text contains Chinese characters"""
        return any('\u4e00' <= char <= '\u9fff' for char in text)

    def translate_text(self, text: str) -> str:
        """Translate Chinese text to English with improved error handling"""
        if not text or not text.strip():
            return "No text provided"
            
        text = text.strip()
        
        if text in self.translation_cache:
            return self.translation_cache[text]
        
        try:
            url = "https://translate.googleapis.com/translate_a/single"
            params = {
                'client': 'gtx',
                'sl': 'zh-CN',
                'tl': 'en',
                'dt': 't',
                'q': text
            }
            
            response = self.session.get(url, params=params, timeout=10)
            if response.status_code == 200:
                result = response.json()
                if result and result[0]:
                    translation = ""
                    for item in result[0]:
                        if item and item[0]:
                            translation += item[0]
                    
                    translation = translation.strip()
                    if translation and translation != text:
                        self.translation_cache[text] = translation
                        return translation
        except Exception as e:
            pass
        
        # Fallback to MyMemory API
        try:
            url = "https://api.mymemory.translated.net/get"
            params = {
                'q': text,
                'langpair': 'zh|en'
            }
            
            response = self.session.get(url, params=params, timeout=8)
            if response.status_code == 200:
                result = response.json()
                if 'responseData' in result and 'translatedText' in result['responseData']:
                    translation = result['responseData']['translatedText']
                    if translation and translation != text:
                        self.translation_cache[text] = translation
                        return translation
        except Exception:
            pass
        
        # Final fallback
        fallback = "Translation unavailable"
        self.translation_cache[text] = fallback
        return fallback

class EnhancedChineseAnalyzer:
    def __init__(self):
        self.pinyin_converter = ComprehensivePinyinConverter()
        
    def get_pinyin(self, text: str) -> str:
        """Get pinyin for any Chinese text"""
        return self.pinyin_converter.get_comprehensive_pinyin(text)
        
    def get_translation(self, text: str) -> str:
        """Get English translation"""
        return self.pinyin_converter.translate_text(text)
    
    def get_character_info(self, char: str) -> Dict[str, str]:
        """Get information about a single character"""
        pinyin = self.get_pinyin(char)
        meaning = self.get_translation(char)
        
        return {
            'pinyin': pinyin,
            'meaning': meaning
        }
    
    def get_word_info(self, word: str) -> Dict[str, str]:
        """Get information about a word"""
        pinyin = self.get_pinyin(word)
        meaning = self.get_translation(word)
        
        return {
            'pinyin': pinyin,
            'meaning': meaning
        }
    
    def analyze_text(self, text: str) -> Tuple[List[Dict], Optional[Dict]]:
        """Analyze Chinese text completely with enhanced error handling"""
        text = text.strip()
        if not text:
            return [], None
        
        try:
            # Get complete sentence analysis
            sentence_pinyin = self.get_pinyin(text)
            sentence_meaning = self.get_translation(text)
            
            sentence_analysis = {
                'pinyin': sentence_pinyin,
                'meaning': sentence_meaning
            }
            
            # Segment into words
            words = list(jieba.cut(text))
            
            analysis = []
            for word in words:
                word = word.strip()
                if not word:
                    continue
                    
                # Only analyze words containing Chinese characters
                has_chinese = any('\u4e00' <= char <= '\u9fff' for char in word)
                if not has_chinese:
                    continue
                
                word_info = self.get_word_info(word)
                
                # Character breakdown for multi-character words
                characters = []
                if len(word) > 1:
                    for char in word:
                        if '\u4e00' <= char <= '\u9fff':
                            char_info = self.get_character_info(char)
                            characters.append({
                                'char': char,
                                'pinyin': char_info['pinyin'],
                                'meaning': char_info['meaning']
                            })
                
                analysis.append({
                    'word': word,
                    'word_pinyin': word_info['pinyin'],
                    'word_meaning': word_info['meaning'],
                    'characters': characters
                })
            
            return analysis, sentence_analysis
            
        except Exception as e:
            st.error(f"Analysis error: {str(e)}")
            return [], None

def main():
    st.markdown('<h1 class="big-font">ğŸ” Perfect Chinese Pinyin Analyzer</h1>', unsafe_allow_html=True)
    st.markdown('<p class="medium-font">Enhanced Multi-Source Pinyin System - Guaranteed Results!</p>', unsafe_allow_html=True)
    
    # Initialize analyzer
    if 'analyzer' not in st.session_state:
        with st.spinner("Initializing enhanced pinyin system..."):
            st.session_state.analyzer = EnhancedChineseAnalyzer()
    
    analyzer = st.session_state.analyzer
    
    # Test the enhanced pinyin system
    col1, col2 = st.columns([1, 1])
    
    with col1:
        if st.button("ğŸ§ª Test Enhanced Pinyin System", type="secondary"):
            test_chars = ["é©", "åˆ", "æˆ‘", "æ„›", "ä½ ", "å­¸", "ç¿’", "æ¼¢", "èª", "å·¥", "ä½œ", "éœ€", "è¦"]
            with st.spinner("Testing enhanced multi-source pinyin system..."):
                st.markdown("### ğŸ” Testing Individual Characters:")
                for char in test_chars:
                    pinyin = analyzer.get_pinyin(char)
                    translation = analyzer.get_translation(char)
                    
                    # Show success/error indicators
                    if '[' not in pinyin and 'pinyin:' not in pinyin:
                        badge = '<span class="success-badge">âœ“ SUCCESS</span>'
                    else:
                        badge = '<span class="error-badge">âš  FALLBACK</span>'
                    
                    st.markdown(f"**{char}** â†’ `{pinyin}` â†’ *{translation}* {badge}", unsafe_allow_html=True)
                    time.sleep(0.1)
    
    with col2:
        if st.button("ğŸ¯ Test Word Combinations", type="secondary"):
            test_words = ["é©åˆ", "æˆ‘æ„›ä½ ", "å·¥ä½œ", "å­¸ç¿’", "æ¼¢èª", "åŒ—äº¬å¤§å­¸"]
            with st.spinner("Testing word combinations..."):
                st.markdown("### ğŸ” Testing Word Combinations:")
                for word in test_words:
                    pinyin = analyzer.get_pinyin(word)
                    translation = analyzer.get_translation(word)
                    
                    if '[' not in pinyin and 'pinyin:' not in pinyin:
                        badge = '<span class="success-badge">âœ“ SUCCESS</span>'
                    else:
                        badge = '<span class="error-badge">âš  PARTIAL</span>'
                    
                    st.markdown(f"**{word}** â†’ `{pinyin}` â†’ *{translation}* {badge}", unsafe_allow_html=True)
                    time.sleep(0.1)
    
    st.markdown("---")
    
    # Input text
    chinese_text = st.text_area(
        "Enter Chinese text (Enhanced system guarantees pinyin for every character!):",
        placeholder="é©åˆæˆ‘çš„å·¥ä½œéœ€è¦å¹«åŠ©",
        help="Enter any Chinese text - the enhanced system uses multiple sources and comprehensive fallbacks",
        height=120
    )
    
    # Analysis options
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        analyze_button = st.button("ğŸš€ Analyze with Enhanced Pinyin", type="primary")
    with col2:
        show_debug = st.checkbox("Show Debug Info", help="Show which methods were used")
    with col3:
        cache_info = st.button("ğŸ“Š Cache Stats")
    
    if cache_info:
        st.info(f"Pinyin Cache: {len(analyzer.pinyin_converter.cache)} entries")
        st.info(f"Translation Cache: {len(analyzer.pinyin_converter.translation_cache)} entries")
    
    if analyze_button and chinese_text:
        st.markdown("---")
        
        with st.spinner('ğŸ” Getting pinyin from enhanced multi-source system...'):
            analysis, sentence_analysis = analyzer.analyze_text(chinese_text)
        
        if sentence_analysis:
            # Sentence-level analysis
            st.markdown('<h2 class="big-font">ğŸ“– Complete Sentence Analysis</h2>', unsafe_allow_html=True)
            st.markdown('<div class="sentence-box">', unsafe_allow_html=True)
            st.markdown(f'<div class="sentence-text">{chinese_text}</div>', unsafe_allow_html=True)
            st.markdown(f'<div class="sentence-pinyin">ğŸµ Pinyin: {sentence_analysis["pinyin"]}</div>', unsafe_allow_html=True)
            st.markdown(f'<div class="sentence-meaning">ğŸ“ Meaning: {sentence_analysis["meaning"]}</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
            st.markdown("---")
            
            # Word-by-word analysis
            if analysis:
                st.markdown('<h2 class="big-font">ğŸ” Detailed Word-by-Word Analysis</h2>', unsafe_allow_html=True)
                
                for i, word_data in enumerate(analysis):
                    word = word_data['word']
                    word_pinyin = word_data['word_pinyin']
                    word_meaning = word_data['word_meaning']
                    characters = word_data['characters']
                    
                    # Word display with enhanced styling
                    st.markdown('<div class="word-box">', unsafe_allow_html=True)
                    st.markdown(f'<div class="chinese-word">{word}</div>', unsafe_allow_html=True)
                    st.markdown(f'<div class="pinyin-highlight">ğŸµ {word_pinyin}</div>', unsafe_allow_html=True)
                    st.markdown(f'<div class="meaning">ğŸ“ {word_meaning}</div>', unsafe_allow_html=True)
                    
                    # Show success indicator
                    if '[' not in word_pinyin and 'pinyin:' not in word_pinyin:
                        st.markdown('<span class="success-badge">âœ… Perfect Pinyin</span>', unsafe_allow_html=True)
                    else:
                        st.markdown('<span class="error-badge">âš ï¸ Fallback Used</span>', unsafe_allow_html=True)
                    
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Character breakdown for multi-character words
                    if len(characters) > 1:
                        st.markdown('<h4 class="medium-font">ğŸ”¤ Character Breakdown:</h4>', unsafe_allow_html=True)
                        
                        # Create columns for characters
                        cols = st.columns(min(len(characters), 4))  # Max 4 columns per row
                        
                        for j, char_data in enumerate(characters):
                            col_idx = j % 4
                            with cols[col_idx]:
                                st.markdown('<div class="character-box">', unsafe_allow_html=True)
                                st.markdown(f'<div class="chinese-char">{char_data["char"]}</div>', unsafe_allow_html=True)
                                st.markdown(f'<div class="pinyin" style="color: #ffd700;">{char_data["pinyin"]}</div>', unsafe_allow_html=True)
                                st.markdown(f'<div class="meaning" style="color: #ffffff; font-size: 18px;">{char_data["meaning"][:25]}{"..." if len(char_data["meaning"]) > 25 else ""}</div>', unsafe_allow_html=True)
                                st.markdown('</div>', unsafe_allow_html=True)
                        
                        # Combination explanation
                        st.markdown('<div class="analysis-box">', unsafe_allow_html=True)
                        st.markdown('<h5 class="medium-font">ğŸ§© Character Combination Logic:</h5>', unsafe_allow_html=True)
                        
                        char_explanations = []
                        for char in characters:
                            short_meaning = char["meaning"].split(",")[0].split("(")[0][:12]
                            char_explanations.append(f'**{char["char"]}** ({char["pinyin"]}: {short_meaning})')
                        
                        explanation = " + ".join(char_explanations) + f' = **{word}**'
                        st.markdown(f'<div class="combination-text">{explanation}</div>', unsafe_allow_html=True)
                        st.markdown(f'<p style="font-size: 20px; color: #555; margin-top: 15px;">Combined meaning: <strong>{word_meaning}</strong></p>', unsafe_allow_html=True)
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Debug information
                    if show_debug:
                        st.markdown('<div class="debug-info">', unsafe_allow_html=True)
                        st.markdown(f"**Debug Info for '{word}':**")
                        st.markdown(f"- Word segmentation: Jieba")
                        st.markdown(f"- Pinyin method: Enhanced multi-source system")
                        st.markdown(f"- Translation method: Google Translate + MyMemory fallback")
                        st.markdown(f"- Character count: {len(characters)} characters")
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    st.markdown("---")
            
            # Summary statistics
            total_chars = sum(len(w['characters']) for w in analysis)
            perfect_pinyin = sum(1 for w in analysis if '[' not in w['word_pinyin'] and 'pinyin:' not in w['word_pinyin'])
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Words Analyzed", len(analysis))
            with col2:
                st.metric("Characters Processed", total_chars)
            with col3:
                st.metric("Perfect Pinyin Rate", f"{perfect_pinyin}/{len(analysis)}")
        
        else:
            st.error("Failed to analyze the text. Please try again or check your input.")
    
    elif chinese_text and not analyze_button:
        st.info("ğŸ‘† Click the analyze button to start processing your Chinese text!")
    
    # Sidebar with examples and features
    with st.sidebar:
        st.markdown('<h3 class="big-font">ğŸ“ Test Examples</h3>', unsafe_allow_html=True)
        
        examples = [
            "é©åˆ",
            "é©åˆæˆ‘",
            "æˆ‘æ„›ä½ ", 
            "ä½ å¥½ä¸–ç•Œ",
            "æˆ‘åœ¨ä¸Šç­",
            "éœ€è¦å¹«åŠ©",
            "ç¸½çµ±åºœ",
            "åŒ—äº¬å¤§å­¸",
            "è¬è¬ä½ çš„å¹«åŠ©",
            "ä¸­å›½äººå­¦ä¹ æ±‰è¯­",
            "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
            "å·¥ä½œå¾ˆå¿™ç¢Œ",
            "é€™å€‹å¾ˆé©åˆæˆ‘çš„å·¥ä½œ",
            "æˆ‘å€‘ä¸€èµ·å­¸ç¿’ä¸­æ–‡",
            "æ¼¢èªæ‹¼éŸ³å¾ˆé‡è¦"
        ]
        
        for example in examples:
            if st.button(f"ğŸ“Œ {example}", key=f"example_{example}"):
                st.session_state.example_clicked = example
        
        if 'example_clicked' in st.session_state:
            # Update the text area by rerunning with the example
            chinese_text = st.session_state.example_clicked
            del st.session_state.example_clicked
            st.rerun()
        
        st.markdown("---")
        st.markdown("### âœ¨ Enhanced Features:")
        st.markdown("ğŸ¯ **Multi-source pinyin lookup**")
        st.markdown("ğŸ“š **Comprehensive built-in dictionary** (2000+ characters)")
        st.markdown("ğŸ”„ **Smart fallback system**")
        st.markdown("ğŸŒ **Multiple translation sources**")
        st.markdown("ğŸ’¾ **Intelligent caching**")
        st.markdown("ğŸ§© **Character breakdown analysis**")
        st.markdown("ğŸ“Š **Success rate tracking**")
        st.markdown("ğŸš« **No character left behind!**")
        
        st.markdown("---")
        st.markdown("### ğŸ”§ Technical Details:")
        st.markdown("- Google Translate API")
        st.markdown("- MyMemory Translation API") 
        st.markdown("- Built-in Pinyin Dictionary")
        st.markdown("- Jieba Word Segmentation")
        st.markdown("- Smart Character Analysis")
        st.markdown("- Multi-level Fallback System")

if __name__ == "__main__":
    main()
